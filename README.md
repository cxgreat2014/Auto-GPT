# Auto-GPT: 一个自主 GPT-4 实验

![GitHub Repo stars](https://img.shields.io/github/stars/Torantulino/auto-gpt?style=social)
[![Twitter Follow](https://img.shields.io/twitter/follow/siggravitas?style=social)](https://twitter.com/SigGravitas)
[![Discord Follow](https://dcbadge.vercel.app/api/server/autogpt?style=flat)](https://discord.gg/autogpt)
[![Unit Tests](https://github.com/Torantulino/Auto-GPT/actions/workflows/ci.yml/badge.svg)](https://github.com/Torantulino/Auto-GPT/actions/workflows/ci.yml)

Auto-GPT 是一个实验性的开源应用程序，展示了 GPT-4 语言模型的能力。这个程序由 GPT-4 驱动，将 LLM“思想”链接在一起，自主地实现你设定的任何目标。作为 GPT-4 完全自主运行的首个例子之一，Auto-GPT 推动了 AI 的可行性边界。

### 演示（2023 年 03 月 30 日）:

https://user-images.githubusercontent.com/22963551/228855501-2f5777cf-755b-4407-a643-c7299e5b6419.mp4

<h2 align="center"> 💖 支持资助 Auto-GPT 的开发 💖</h2>
<p align="center">
如果您愿意捐赠咖啡，您可以帮助支付开发 Auto-GPT 的 API 成本，推动完全自主的 AI 边界！
一整天的开发成本可以轻松达到 20 美元，这对于一个免费项目而言相当有限制性。
您的支持将不胜感激。
</p>

<p align="center">
<a href="https://github.com/Torantulino/Auto-GPT/graphs/contributors">贡献者</a>和<a href="https://github.com/sponsors/Torantulino">赞助商</a>使这个免费、开源项目的开发成为可能。如果您想赞助这个项目，并让您的头像或公司标志出现在下面<a href="https://github.com/sponsors/Torantulino">请点击此处</a>。

<h3 align="center">个人赞助商</h3>
<p align="center">
<a href="https://github.com/robinicus"><img src="https://github.com/robinicus.png" width="50px" alt="robinicus" /></a>&nbsp;&nbsp;<a href="https://github.com/prompthero"><img src="https://github.com/prompthero.png" width="50px" alt="prompthero" /></a>&nbsp;&nbsp;<a href="https://github.com/crizzler"><img src="https://github.com/crizzler.png" width="50px" alt="crizzler" /></a>&nbsp;&nbsp;<a href="https://github.com/tob-le-rone"><img src="https://github.com/tob-le-rone.png" width="50px" alt="tob-le-rone" /></a>&nbsp;&nbsp;<a href="https://github.com/FSTatSBS"><img src="https://github.com/FSTatSBS.png" width="50px" alt="FSTatSBS" /></a>&nbsp;&nbsp;<a href="https://github.com/toverly1"><img src="https://github.com/toverly1.png" width="50px" alt="toverly1" /></a>&nbsp;&nbsp;<a href="https://github.com/ddtarazona"><img src="https://github.com/ddtarazona.png" width="50px" alt="ddtarazona" /></a>&nbsp;&nbsp;<a href="https://github.com/Nalhos"><img src="https://github.com/Nalhos.png" width="50px" alt="Nalhos" /></a>&nbsp;&nbsp;<a href="https://github.com/Kazamario"><img src="https://github.com/Kazamario.png" width="50px" alt="Kazamario" /></a>&nbsp;&nbsp;<a href="https://github.com/pingbotan"><img src="https://github.com/pingbotan.png" width="50px" alt="pingbotan" /></a>&nbsp;&nbsp;<a href="https://github.com/indoor47"><img src="https://github.com/indoor47.png" width="50px" alt="indoor47" /></a>&nbsp;&nbsp;<a href="https://github.com/AuroraHolding"><img src="https://github.com/AuroraHolding.png" width="50px" alt="AuroraHolding" /></a>&nbsp;&nbsp;<a href="https://github.com/kreativai"><img src="https://github.com/kreativai.png" width="50px" alt="kreativai" /></a>&nbsp;&nbsp;<a href="https://github.com/hunteraraujo"><img src="https://github.com/hunteraraujo.png" width="50px" alt="hunteraraujo" /></a>&nbsp;&nbsp;<a href="https://github.com/Explorergt92"><img src="https://github.com/Explorergt92.png" width="50px" alt="Explorergt92" /></a>&nbsp;&nbsp;<a href="https://github.com/judegomila"><img src="https://github.com/judegomila.png" width="50px" alt="judegomila" /></a>&nbsp;&nbsp;
<a href="https://github.com/thepok"><img src="https://github.com/thepok.png" width="50px" alt="thepok" /></a>
&nbsp;&nbsp;<a href="https://github.com/SpacingLily"><img src="https://github.com/SpacingLily.png" width="50px" alt="SpacingLily" /></a>&nbsp;&nbsp;<a href="https://github.com/merwanehamadi"><img src="https://github.com/merwanehamadi.png" width="50px" alt="merwanehamadi" /></a>&nbsp;&nbsp;<a href="https://github.com/m"><img src="https://github.com/m.png" width="50px" alt="m" /></a>&nbsp;&nbsp;<a href="https://github.com/zkonduit"><img src="https://github.com/zkonduit.png" width="50px" alt="zkonduit" /></a>&nbsp;&nbsp;<a href="https://github.com/maxxflyer"><img src="https://github.com/maxxflyer.png" width="50px" alt="maxxflyer" /></a>&nbsp;&nbsp;<a href="https://github.com/tekelsey"><img src="https://github.com/tekelsey.png" width="50px" alt="tekelsey" /></a>&nbsp;&nbsp;<a href="https://github.com/digisomni"><img src="https://github.com/digisomni.png" width="50px" alt="digisomni" /></a>&nbsp;&nbsp;<a href="https://github.com/nocodeclarity"><img src="https://github.com/nocodeclarity.png" width="50px" alt="nocodeclarity" /></a>&nbsp;&nbsp;<a href="https://github.com/tjarmain"><img src="https://github.com/tjarmain.png" width="50px" alt="tjarmain" /></a>
</p>

## 目录

- [Auto-GPT：一个自主的GPT-4实验](#auto-gpt-an-autonomous-gpt-4-experiment)
  - [演示（2023年3月30日）：](#demo-30032023)
  - [目录](#table-of-contents)
  - [🚀 特点](#-features)
  - [📋 要求](#-requirements)
  - [💾 安装](#-installation)
  - [🔧 用法](#-usage)
    - [日志](#logs)
  - [🗣️ 语音模式](#️-speech-mode)
  - [🔍 Google API密钥配置](#-google-api-keys-configuration)
    - [设置环境变量](#setting-up-environment-variables)
  - [Redis设置](#redis-setup)
  - [🌲 Pinecone API密钥设置](#-pinecone-api-key-setup)
    - [设置环境变量](#setting-up-environment-variables-1)
  - [设置缓存类型](#setting-your-cache-type)
  - [查看内存使用情况](#view-memory-usage)
  - [💀 持续模式 ⚠️](#-continuous-mode-️)
  - [仅支持GPT3.5模式](#gpt35-only-mode)
  - [🖼 图像生成](#-image-generation)
  - [⚠️ 限制](#️-limitations)
  - [🛡 免责声明](#-disclaimer)
  - [🐦 在Twitter上与我们联系](#-connect-with-us-on-twitter)
  - [运行测试](#run-tests)
  - [运行lint程序](#run-linter)

## 🚀 特点

- 🌐 可以访问互联网以进行搜索和信息收集
- 💾 长期和短期记忆管理
- 🧠 GPT-4实例用于文本生成
- 🔗 访问流行的网站和平台
- 🗃️ 带有GPT-3.5的文件存储和摘要

## 📋 要求

- 环境（只需选择一个）
  - [vscode + devcontainer](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)：它已在.devcontainer文件夹中进行了配置，可以直接使用
  - [Python 3.8或更高版本](https://www.tutorialspoint.com/how-to-install-python-in-windows)
- [OpenAI API密钥](https://platform.openai.com/account/api-keys)
- [PINECONE API密钥](https://www.pinecone.io/)

可选：

- [ElevenLabs密钥](https://elevenlabs.io/) （如果希望AI能够说话）

## 💾 安装

要安装Auto-GPT，请按照以下步骤操作：

1. 确保您具有上面列出的所有**要求**，如果没有，请安装/获取它们。

_以下命令应在CMD、Bash或Powershell窗口中执行。为此，转到计算机上的文件夹，在文件夹路径上单击，然后键入CMD，然后按Enter键。_

2. 克隆存储库：
   对于此步骤，您需要已安装Git，但是您可以通过单击此页面顶部的按钮下载zip文件而不是安装Git☝️

```
git clone https://github.com/Torantulino/Auto-GPT.git
```

3. 导航到项目目录：
   （在CMD窗口中键入此内容，您的目标是导航CMD窗口到刚刚下载的存储库）

```
cd 'Auto-GPT'
```

4. 安装所需的依赖项：
   （再次，在CMD窗口中键入此内容）

```
pip install -r requirements.txt
```

5. 将`.env.template`重命名为`.env`，并填写您的`OPENAI_API_KEY`。如果您计划使用语音模式，请填写您的`ELEVEN_LABS_API_KEY`。
  - 从此处获取您的OpenAI API密钥：https://platform.openai.com/account/api-keys。
  - 从这里获取您的ElevenLabs API密钥：https://elevenlabs.io。您可以使用网站上的“个人资料”选项卡查看您的xi-api-key。
  - 如果要在Azure实例上使用GPT，请将`USE_AZURE`设置为`True`，然后：
    - 将`azure.yaml.template`重命名为`azure.yaml`，并在`azure_model_map`部分提供相关模型的`azure_api_base`、`azure_api_version`和所有部署ID：
      - `fast_llm_model_deployment_id`-您的gpt-3.5-turbo或gpt-4部署ID
      - `smart_llm_model_deployment_id`-您的gpt-4部署ID
      - `embedding_model_deployment_id`-您的文本嵌入ada-002 v2部署ID
    - 请将所有这些值指定为双引号字符串
    - 详细信息可以在此处找到：https://pypi.org/project/openai/中的“Microsoft Azure Endpoints”部分，以及此处：https://learn.microsoft.com/en-us/azure/cognitive-services/openai/tutorials/embeddings?tabs=command-line有关嵌入模型的信息。

## 🔧 用法

1. 在终端中运行`main.py` Python脚本：
   （在CMD窗口中键入此内容）

```
python scripts/main.py
```

2. 在AUTO-GPT的每个操作之后，键入“NEXT COMMAND”以授权它们继续进行。
3. 要退出程序，请键入“exit”，然后按Enter键。

### 日志

您将在文件夹`./output/logs`中找到活动和错误日志。

要输出调试日志：

```
python scripts/main.py --debug
```

## 🗣️ 语音模式

使用此选项在Auto-GPT中使用TTS

```
python scripts/main.py --speak
```

## 🔍 Google API Keys Configuration

This section is optional, use the official google api if you are having issues with error 429 when running a google search.
To use the `google_official_search` command, you need to set up your Google API keys in your environment variables.

1. Go to the [Google Cloud Console](https://console.cloud.google.com/).
2. If you don't already have an account, create one and log in.
3. Create a new project by clicking on the "Select a Project" dropdown at the top of the page and clicking "New Project". Give it a name and click "Create".
4. Go to the [APIs & Services Dashboard](https://console.cloud.google.com/apis/dashboard) and click "Enable APIs and Services". Search for "Custom Search API" and click on it, then click "Enable".
5. Go to the [Credentials](https://console.cloud.google.com/apis/credentials) page and click "Create Credentials". Choose "API Key".
6. Copy the API key and set it as an environment variable named `GOOGLE_API_KEY` on your machine. See setting up environment variables below.
7. Go to the [Custom Search Engine](https://cse.google.com/cse/all) page and click "Add".
8. Set up your search engine by following the prompts. You can choose to search the entire web or specific sites.
9. Once you've created your search engine, click on "Control Panel" and then "Basics". Copy the "Search engine ID" and set it as an environment variable named `CUSTOM_SEARCH_ENGINE_ID` on your machine. See setting up environment variables below.

_Remember that your free daily custom search quota allows only up to 100 searches. To increase this limit, you need to assign a billing account to the project to profit from up to 10K daily searches._

### Setting up environment variables

For Windows Users:

```
setx GOOGLE_API_KEY "YOUR_GOOGLE_API_KEY"
setx CUSTOM_SEARCH_ENGINE_ID "YOUR_CUSTOM_SEARCH_ENGINE_ID"

```

For macOS and Linux users:

```
export GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
export CUSTOM_SEARCH_ENGINE_ID="YOUR_CUSTOM_SEARCH_ENGINE_ID"

```

## Redis Setup

Install docker desktop.

Run:

```
docker run -d --name redis-stack-server -p 6379:6379 redis/redis-stack-server:latest
```

See https://hub.docker.com/r/redis/redis-stack-server for setting a password and additional configuration.

Set the following environment variables:

```
MEMORY_BACKEND=redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
```

Note that this is not intended to be run facing the internet and is not secure, do not expose redis to the internet without a password or at all really.

You can optionally set

```
WIPE_REDIS_ON_START=False
```

To persist memory stored in Redis.

You can specify the memory index for redis using the following:

```
MEMORY_INDEX=whatever
```

## 🌲 Pinecone API Key Setup

Pinecone enables the storage of vast amounts of vector-based memory, allowing for only relevant memories to be loaded for the agent at any given time.

1. Go to [pinecone](https://app.pinecone.io/) and make an account if you don't already have one.
2. Choose the `Starter` plan to avoid being charged.
3. Find your API key and region under the default project in the left sidebar.

### Setting up environment variables

Simply set them in the `.env` file.

Alternatively, you can set them from the command line (advanced):

For Windows Users:

```
setx PINECONE_API_KEY "YOUR_PINECONE_API_KEY"
setx PINECONE_ENV "Your pinecone region" # something like: us-east4-gcp

```

For macOS and Linux users:

```
export PINECONE_API_KEY="YOUR_PINECONE_API_KEY"
export PINECONE_ENV="Your pinecone region" # something like: us-east4-gcp

```

## Setting Your Cache Type

By default Auto-GPT is going to use LocalCache instead of redis or Pinecone.

To switch to either, change the `MEMORY_BACKEND` env variable to the value that you want:

`local` (default) uses a local JSON cache file
`pinecone` uses the Pinecone.io account you configured in your ENV settings
`redis` will use the redis cache that you configured

## View Memory Usage

1. View memory usage by using the `--debug` flag :)

## 💀 Continuous Mode ⚠️

Run the AI **without** user authorisation, 100% automated.
Continuous mode is not recommended.
It is potentially dangerous and may cause your AI to run forever or carry out actions you would not usually authorise.
Use at your own risk.

1. Run the `main.py` Python script in your terminal:

```
python scripts/main.py --continuous

```

2. To exit the program, press Ctrl + C

## GPT3.5 ONLY Mode

If you don't have access to the GPT4 api, this mode will allow you to use Auto-GPT!

```
python scripts/main.py --gpt3only
```

It is recommended to use a virtual machine for tasks that require high security measures to prevent any potential harm to the main computer's system and data.

## 🖼 Image Generation

By default, Auto-GPT uses DALL-e for image generation. To use Stable Diffusion, a [HuggingFace API Token](https://huggingface.co/settings/tokens) is required.

Once you have a token, set these variables in your `.env`:

```
IMAGE_PROVIDER=sd
HUGGINGFACE_API_TOKEN="YOUR_HUGGINGFACE_API_TOKEN"
```

## ⚠️ Limitations

This experiment aims to showcase the potential of GPT-4 but comes with some limitations:

1. Not a polished application or product, just an experiment
2. May not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!
3. Quite expensive to run, so set and monitor your API key limits with OpenAI!

## 🛡 Disclaimer

Disclaimer
This project, Auto-GPT, is an experimental application and is provided "as-is" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.

The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.

**Please note that the use of the GPT-4 language model can be expensive due to its token usage.** By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.

As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.

By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.

## 🐦 Connect with Us on Twitter

Stay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.

- **Developer**: Follow [@siggravitas](https://twitter.com/siggravitas) for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.
- **Entrepreneur-GPT**: Join the conversation with the AI itself by following [@En_GPT](https://twitter.com/En_GPT). Share your experiences, discuss the AI's outputs, and engage with the growing community of users.

We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!

<p align="center">
  <a href="https://star-history.com/#Torantulino/auto-gpt&Date">
    <img src="https://api.star-history.com/svg?repos=Torantulino/auto-gpt&type=Date" alt="Star History Chart">
  </a>
</p>

## Run tests

To run tests, run the following command:

```
python -m unittest discover tests
```

To run tests and see coverage, run the following command:

```
coverage run -m unittest discover tests
```

## Run linter

This project uses [flake8](https://flake8.pycqa.org/en/latest/) for linting. We currently use the following rules: `E303,W293,W291,W292,E305,E231,E302`. See the [flake8 rules](https://www.flake8rules.com/) for more information.

To run the linter, run the following command:

```
flake8 scripts/ tests/

# Or, if you want to run flake8 with the same configuration as the CI:
flake8 scripts/ tests/ --select E303,W293,W291,W292,E305,E231,E302
```
